# 1. Modules

Each file is a module, and modules import other modules to use the names they define. Modules might also correspond to extensions coded in external languages such as C, Java, or C#, and even to directories in package imports. Modules are processed with two statements and one important function:

**import**

>  Lets a client (importer) fetch a module as a whole 

**from**

> Allows clients to fetch particular names from a module 

**imp.reload (reload in 2.X)**

> Provides a way to reload a module’s code without stopping Python



## Why Use Modules?

- **Code reuse**

  modules let you save code in files permanently. code in module files is persistent—it can be reloaded and rerun as many times as needed. Just as importantly, modules are a place to define names, known as attributes, which may be referenced by multiple external clients. When used well, this supports a modular program design that groups functionality into reusable units.


- **System namespace partitioning**

  Modules are also the highest-level program organization unit in Python. Although they are fundamentally just packages of names, these packages are also self-contained. Much like the local scopes of functions, this helps avoid name clashes across your programs.

- **Implementing shared services or data**

  From an operational perspective, modules are also useful for implementing components that are shared across a system and hence require only a single copy.



## Python Program Architecture

### How to Structure a Program

program consists of text files containing Python statements, with one main top-level file, and zero or more supplemental files known as modules.

Here’s how this works. The top-level (a.k.a. script) file contains the main flow of control of your program—this is the file you run to launch your application. The module files are libraries of tools used to collect components used by the top-level file, and possibly elsewhere. Top-level files use tools defined in module files, and modules use tools defined in other modules.

Although they are files of code too, module files generally don’t do anything when run directly; rather, they define tools intended for use in other files. A file imports a module to gain access to the tools it defines, which are known as its attributes—variable names attached to objects such as functions. Ultimately, we import modules and access their attributes to use their tools.

### How Imports Work

in Python, imports are not just textual insertions of one file into another. They are really runtime operations that perform three distinct steps the first time a program imports a given file:

1. Find the module’s file.
2. Compile it to byte code (if needed).
3. Run the module’s code to build the objects it defines.

all three of these steps are carried out only the first time a module is imported during a program’s execution; later imports of the same module in a program run bypass all of these steps and simply fetch the already loaded module object in memory.Technically, Python does this by storing loaded modules in a table named `sys.modules` and checking there at the start of an import operation. If the module is not present, a three-step process begins.

#### 1. Find the module’s file.

Python must locate the module file referenced by an import statement. 

#### 2. Compile it to byte code (if needed).

After finding a source code file that matches an import statement by traversing the module search path, Python next compiles it to byte code, During an import operation Python checks both file modification times and the byte code’s Python version number to decide how to proceed. The former uses file “timestamps,” and the latter uses either a “magic” number embedded in the byte code or a filename, depending on the Python release being used. This step chooses an action as follows:

- **Compile**

  If the byte code file is older than the source file (i.e., if you’ve changed the source) or was created by a different Python version, Python automatically regenerates the byte code when the program is run.

  As discussed ahead, this model is modified somewhat in Python 3.2 and later—byte code files are segregated in a `__pycache__` subdirectory and named with their Python version to avoid contention and recompiles when multiple Pythons are installed. This obviates the need to check version numbers in the byte code, but the timestamp check is still used to detect changes in the source.


- **Don’t compile**

  If, on the other hand, Python finds a .pyc byte code file that is not older than the corresponding .py source file and was created by the same Python version, it skips the source-to-byte-code compile step.

  In addition, if Python finds only a byte code file on the search path and no source, it simply loads the byte code directly; this means you can ship a program as just byte code files and avoid sending source. In other words, the compile step is by-passed if possible to speed program startup.

compilation happens when a file is being imported. The byte code of top-level files is used internally and discarded; byte code of imported files is saved in files to speed future imports.

#### 3. Run the module’s code to build the objects it defines.

The final step of an import operation executes the byte code of the module. All statements in the file are run in turn, from top to bottom, and any assignments made to names during this step generate attributes of the resulting module object.



## Byte Code Files: `__pycache__` in Python 3.2+

- **In Python 3.1 and earlier (including all of Python 2.X)** 

  Byte code is stored in files in the same directory as the corresponding source files, normally with the filename extension .pyc (e.g., module.pyc). Byte code files are also stamped internally with the version of Python that created them (known as a “magic” field to developers) so Python knows to recompile when this differs in the version of Python running your program. For instance, if you upgrade to a new Python whose byte code differs, all your byte code files will be recompiled automatically due to a version number mismatch, even if you haven’t changed your source code.


- **In Python 3.2 and later** 

  Byte code is instead stored in files in a subdirectory named `__pycache__`, which Python creates if needed, and which is located in the directory containing the corresponding source files. This helps avoid clutter in your source directories by segregating the byte code files in their own directory. In addition, although byte code files still get the .pyc extension as before, they are given more descriptive names that include text identifying the version of Python that created them (e.g., mod-ule.cpython-32.pyc). This avoids contention and recompiles: because each version of Python installed can have its own uniquely named version of byte code files in the `__pycache__` subdirectory, running under a given version doesn’t overwrite the byte code of another, and doesn’t require recompiles. Technically, byte code filenames also include the name of the Python that created them, so CPython, Jython, and other implementations mentioned in the preface and  can coexist on the same machine without stepping on each other’s work (once they support this model).

In both models, Python always recreates the byte code file if you’ve changed the source code file since the last compile,

#### Byte Code File Models in Action

#### ...



## The Module Search Path / 模块搜索路径

1. The home directory of the program
2. PYTHONPATH directories (if set)
3. Standard library directories
4. The contents of any .pth files (if present)
5. The site-packages home of third-party extensions

- **1. Home directory (automatic)**

  Python first looks for the imported file in the home directory. The meaning of this entry depends on how you are running the code. When you’re running a pro-gram, this entry is the directory containing your program’s top-level script file. When you’re working interactively, this entry is the directory in which you are working (i.e., the current working directory).

  Because this directory is always searched first, if a program is located entirely in a single directory, all of its imports will work automatically with no path configuration required. On the other hand, because this directory is searched first, its files will also override modules of the same name in directories elsewhere on the path; be careful not to accidentally hide library modules this way if you need them in your program, or use package tools we’ll meet later that can partially sidestep this issue.


- **2. PYTHONPATH directories (configurable)**

  Next, Python searches all directories listed in your PYTHONPATH environment variable setting, from left to right (assuming you have set this at all: it’s not preset for you). In brief, PYTHONPATH is simply a list of user-defined and platform-specific names of directories that contain Python code files. You can add all the directories from which you wish to be able to import, and Python will extend the module search path to include all the directories your PYTHONPATH lists.

  Because Python searches the home directory first, this setting is only important when importing files across directory boundaries—that is, if you need to import a file that is stored in a different directory from the file that imports it. You’ll probably want to set your PYTHONPATH variable once you start writing substantial programs, but when you’re first starting out, as long as you save all your module files in the directory in which you’re working (i.e., the home directory, like the C:\code used in this book) your imports will work without you needing to worry about this setting at all.

- **3. Standard library directories (automatic)**

  Next, Python automatically searches the directories where the standard library modules are installed on your machine. Because these are always searched, they normally do not need to be added to your PYTHONPATH or included in path files (discussed next).

- **4      .pth path file directories (configurable)**

  Next, a lesser-used feature of Python allows users to add directories to the module search path by simply listing them, one per line, in a text file whose name ends with a .pth suffix (for “path”). These path configuration files are a somewhat advanced installation-related feature; we won’t cover them fully here, but they provide an alternative to PYTHONPATH settings.



### The sys.path List

If you want to see how the module search path is truly configured on your machine, you can always inspect the path as Python knows it by printing the built-in `sys.path` list (that is, the path attribute of the standard library module sys). This list of directory name strings is the actual search path within Python; on imports, Python searches each directory in this list from left to right, and uses the first file match it finds.

Really, `sys.path` is the module search path. Python configures it at program startup, automatically merging the home directory of the top-level file (or an empty string to designate the current working directory), any PYTHONPATH directories, the contents of any .pth file paths you’ve created, and all the standard library directories. The result is a list of directory name strings that Python searches on each import of a new file.

```
>>> import sys
>>> sys.path 
['', 'C:\\code', 'C:\\Windows\\system32\\python33.zip', 'C:\\Python33\\DLLs', 'C:\\Python33\\lib', 'C:\\Python33', 'C:\\Users\\mark', 'C:\\Python33\\lib\\site-packages']
```



### Module File Selection

filename extensions (e.g., .py) are omitted from import statements intentionally.

#### Module sources

For example, an `import` statement of the form `import b` might today load or resolve to:

- A source code file named b.py


- A byte code file named b.pyc



- An optimized byte code file named b.pyo (a less common format)



- A directory named b, for package imports 



- A compiled extension module, coded in C, C++, or another language, and dynamically linked when imported (e.g., b.so on Linux, or b.dll or b.pyd on Cygwin and Windows)



- A compiled built-in module coded in C and statically linked into Python



- A ZIP file component that is automatically extracted when imported



- An in-memory image, for frozen executables



- A Java class, in the Jython version of Python



- A .NET component, in the IronPython version of Python



# 2. Module Coding Basics

When a module is imported, Python maps the internal module name to an external filename by adding a directory path from the module search path to the front, and a .py or other extension at the end. For instance, a module named M ultimately maps to some external file `<directory>\M.<extension>` that contains the module’s code.



## Module Usage

Clients can use the simple module file we just wrote by running an import or from statement. Both statements find, compile, and run a module file’s code, if it hasn’t yet been loaded. The chief difference is that `import` fetches the module as a whole, so you must qualify to fetch its names; in contrast, `from` fetches (or copies) specific names out of the module.

#### The import Statement

it identifies an external file to be loaded, and it becomes a variable in the script, which references the module object after the file is loaded:

```
>>> import module1							# Get module as a whole (one or more)
>>> module1.printer('Hello world!') 		# Qualify to get names
Hello world!
```

Because it gives a name that refers to the whole module object, we must go through the module name to fetch its attributes (e.g., module1.printer).

#### The from Statement

because from copies specific names from one file over to another scope, it allows us to use the copied names directly in the script without going through the module (e.g., `printer`):

```
>>> from module1 import printer			# Copy out a variable (one or more)
>>> printer('Hello world!') 			# No need to qualify name
Hello world!
```

#### The from * Statement

a special form of from: when we use a * instead of specific names, we get copies of all names assigned at the top level of the referenced module. 

Here again, we can then use the copied name `printer` in our script without going through the module name:

```
>>> from module1 import *				# Copy out _all_ variables
>>> printer('Hello world!') 
Hello world!
```

#### Imports Happen Only Once

**Modules are loaded and run on the first `import` or `from`, and only the first.** This is on purpose—because importing is an expensive operation, by default Python does it just once per file, per process. Later import operations simply fetch the already loaded module object.

**Example :**

```
print('hello')
spam = 1				# Initialize variable

% python
>>> import simple 		# First import: loads and runs file's code
hello
>>> simple.spam 		# Assignment makes an attribute
1

>>> simple.spam = 2		# Change attribute in module
>>> import simple		# Just fetches already loaded module
>>> simple.spam 		# Code wasn't rerun: attribute unchanged
2
```



#### import and from Are Assignments

Just like `def`, `import` and `from` are executable statements, not compile-time declarations. They may be nested in `if` tests, to select among options; appear in function `def`s, to be loaded only on calls (subject to the preceding note); be used in `try` statements, to provide defaults; and so on. They are not resolved or run until Python reaches them while executing your program. In other words, imported modules and names are not available until their associated import or from statements run.

##### Changing mutables in modules

like `def`, the `import` and `from` are implicit assignments:

- **import** assigns an entire module object to a single name.


- **from** assigns one or more names to objects of the same names in another module.

**Example :**

```
small.py:
x = 1 
y = [1, 2]

% python
>>> from small import x, y		# Copy two names out
>>> x = 42						# Changes local x only 
>>> y[0] = 42					# Changes shared mutable in place
```

`x` is not a shared mutable object, but `y` is.

```
>>> import small				# Get module name (from doesn't)
>>> small.x 					# Small's x is not my x
1
>>> small.y 					# But we share a changed mutable
[42, 2]
```
##### Cross-file name changes

there is no link from a name copied with `from` back to the file it came from. To really change a global name in another file, you must use `import`:

```
% python
>>> from small import x, y		# Copy two names out
>>> x = 42						# Changes my x only

>>> import small				# Get module name
>>> small.x = 42				# Changes x in other module
```



#### import and from Equivalence

`from` only copies names from one module to another; it does not assign the module name itself. At least conceptually, a `from` statement like this one:

```
from module import name1, name2		# Copy these two names out (only)
```

is equivalent to this statement sequence:

```
import module 						# Fetch the module object
name1 = module.name1 				# Copy names out by assignment
name2 = module.name2 
del module							# Get rid of the module name
```

> the `from` statement creates new variables in the importer, which initially refer to objects of the same names in the imported file. Only the names are copied out, though, not the objects they reference, and not the name of the module itself. When we use the `from *` form of this statement (`from module import *`), the equivalence is the same, but all the top-level names in the module are copied over to the importing scope this way.
>
> the first step of the `from` runs a normal `import` operation, the `from` always imports the entire module into memory if it has not yet been imported, regardless of how many names it copies out of the file.



#### Potential Pitfalls of the from Statement

It is true that the `from` statement has the potential to corrupt namespaces, at least in principle—if you use it to import variables that happen to have the same names as existing variables in your scope, your variables will be silently overwritten. This problem doesn’t occur with the simple `import` statement because you must always go through a module’s name to get to its contents (`module.attr` will not clash with a variable named `attr` in your scope). As long as you understand and expect that this can happen when using `from`, though, this isn’t a major concern in practice, especially if you list the imported names explicitly (e.g., `from module import x, y, z`).

the `from` statement has more serious issues when used in conjunction with the `reload` call, as imported names might reference prior versions of objects. Moreover, the `from module import *` form really can corrupt namespaces and make names difficult to understand, especially when applied to more than one file—in this case, there is no way to tell which module a name came from, short of searching the external source files. In effect, the `from *` form collapses one namespace into another, and so defeats the namespace partitioning feature of modules.

Probably the best real-world advice here is to generally prefer `import` to `from` for simple modules, to explicitly list the variables you want in most `from` statements, and to limit the `from *` form to just one import per file. That way, any undefined names can be assumed to live in the module referenced with the `from *`.

##### When import is required

The only time you really must use `import` instead of `from` is when you must use the same name defined in two different modules. For example, if two files define the same name differently:

```
# M.py 
def func():
	...do something...

# N.py 
def func():
	...do something else...
```

and you must use both versions of the name in your program, the `from` statement will fail—you can have only one assignment to the name in your scope:

```
# O.py 
from M import func 
from N import func 			# This overwrites the one we fetched from M
func()						# Calls N.func only!
```

An `import` will work here, though, because including the name of the enclosing module makes the two names unique:

```
# O.py 
import M, N			# Get the whole modules, not their names
M.func()			# We can call both names now
N.func()			# The module names make them unique
```

`import` allows you to avoid the name collision. Another way out of this dilemma is using the `as` extension,

```
# O.py 
from M import func as mfunc 		# Rename uniquely with "as"
from N import func as nfunc 
mfunc(); nfunc()					# Calls one or the other
```

The `as` extension works in both `import` and `from` as a simple renaming tool (it can also be used to give a shorter synonym for a long module name in `import`)



## Module Namespaces

### Files Generate Namespaces

every name that is assigned a value at the top level of a module file (i.e., not nested in a function or class body) becomes an attribute of that module.

For instance, given an assignment statement such as `X = 1` at the top level of a module file M.py, the name `X` becomes an attribute of `M`, which we can refer to from outside the module as `M.X`. The name `X` also becomes a global variable to other code inside M.py, but we need to consider the notion of module loading and scopes a bit more formally to understand why:

- **Module statements run on the first import**. The first time a module is imported anywhere in a system, Python creates an empty module object and executes the statements in the module file one after another, from the top of the file to the bottom.


- **Top-level assignments create module attributes**. During an import, statements at the top level of the file not nested in a `def` or `class` that assign names (e.g., =, def) create attributes of the module object; assigned names are stored in the module’s namespace.


- **Module namespaces can be accessed via the attribute `__dict__` or `dir(M)`**. Module namespaces created by imports are dictionaries; they may be accessed through the built-in `__dict__` attribute associated with module objects and may be inspected with the dir function. The dir function is roughly equivalent to the sorted keys list of an object’s `__dict__` attribute, but it includes inherited names for classes, may not be complete, and is prone to changing from release to release.


- **Modules are a single scope (local is global)**. names at the top level of a module follow the same reference/assignment rules as names in a function, but the local and global scopes are the same—or, more formally, they follow the LEGB scope rule, but without the L and E lookup layers.

  Crucially, though, the module’s global scope becomes an attribute dictionary of a module object after the module has been loaded. Unlike function scopes, where the local namespace exists only while the function runs, a module file’s scope becomes a module object’s attribute namespace and lives on after the import, providing a source of tools to importers.

Example: Suppose we create the following module file in a text editor and call it module2.py:

```
print('starting to load...') 
import sys 
name = 42

def func(): pass
class klass: pass

print('done loading.')
```

The first time this module is imported (or run as a program), Python executes its statements from top to bottom. Some statements create names in the module’s namespace as a side effect, but others do actual work while the import is going on. For instance, the two `print` statements in this file execute at import time:

```
>>> import module2 
starting to load... 
done loading.
```

Once the module is loaded, its scope becomes an attribute namespace in the module object we get back from `import`. We can then access attributes in this namespace by qualifying them with the name of the enclosing module:

```
>>> module2.sys 
<module 'sys' (built-in)>

>>> module2.name 
42

>>> module2.func 
<function func at 0x000000000222E7B8>

>>> module2.klass 
<class 'module2.klass'>
```

Here, `sys`, `name`, `func`, and `klass` were all assigned while the module’s statements were being run, so they are attributes after the import. but notice the `sys` attribute—`import` statements really assign module objects to names, and any type of assignment to a name at the top level of a file generates a module attribute.



### Namespace Dictionaries: `__dict__`

internally, module namespaces are stored as dictionary objects. These are just normal dictionaries with all the usual methods.

we can access a module’s namespace dictionary through the module’s `__dict__` attribute. Continuing the prior section’s example (remember to wrap this in a list call in Python 3.X—it’s a view object there, and contents may vary outside 3.3 used here):

```
>>> list(module2.__dict__.keys()) 
['__loader__', 'func', 'klass', '__builtins__', '__doc__', '__file__', '__name__', 'name', '__package__', 'sys', '__initializing__', '__cached__']
```

The names we assigned in the module file become dictionary keys internally, so some of the names here reflect top-level assignments in our file. However, Python also adds some names in the module’s namespace for us

```
>>> list(name for name in module2.__dict__.keys() if not name.startswith('__')) 
['func', 'klass', 'name', 'sys']
>>> list(name for name in module2.__dict__ if not name.startswith('__')) 
['func', 'sys', 'name', 'klass']

>>> module2.name, module2.__dict__['name'] 
(42, 42)
```



### Attribute Name Qualification

In Python, you can access the attributes of any object that has attributes using the qualification (a.k.a. attribute fetch) syntax `object.attribute`.

attribute qualification has nothing to do with the scope rules

The LEGB scope rule applies only to bare, unqualified names. it may be used for the leftmost name in a name path, but later names after dots search specific objects instead. Here are the rules:

**Simple variables** 

> `X` means search for the name `X` in the current scopes (following the LEGB rule)

**Qualification**

> `X.Y` means find `X` in the current scopes, then search for the attribute `Y` in the object `X` (not in scopes).

**Qualification paths**

> `X.Y.Z` means look up the name `Y` in the object `X`, then look up `Z` in the object `X.Y`.

**Generality**

> Qualification works on all objects with attributes: modules, classes, C extension types, etc.



### Imports Versus Scopes

import operations never give upward visibility to code in imported files —an imported file cannot see names in the importing file. More formally:

- Functions can never see names in other functions, unless they are physically enclosing.
- Module code can never see names in other modules, unless they are explicitly imported.

in Python, the scopes surrounding a piece of code are completely determined by the code’s physical position in your file. Scopes are never influenced by function calls or module imports



### Namespace Nesting

imports do not nest namespaces upward, they do nest downward.

**For example**, consider the next three files. `mod3.py` defines a single global name and attribute by assignment:

```
X = 3
```

`mod2.py` in turn defines its own `X`, then `imports mod3` and uses qualification to access the imported module’s attribute:

```
X = 2 
import mod3

print(X, end=' ') 		# My global X
print(mod3.X)			# mod3's X
```

`mod1.py` also defines its own `X`, then imports `mod2`, and fetches attributes in both the first and second files:

```
X = 1 
import mod2

print(X, end=' ') 		 # My global X
print(mod2.X, end=' ') 	 # mod2's X
print(mod2.mod3.X)		 # Nested mod3's X
```

when `mod1` imports `mod2` here, it sets up a two-level namespace nesting. By using the path of names `mod2.mod3.X`, it can descend into `mod3`, which is nested in the imported `mod2`. The net effect is that `mod1` can see the `X`s in all three files, and hence has access to all three global scopes:

```
% python mod1.py 
2 3 
1 2 3
```



## Reloading Modules

a module’s code is run only once per process by default. To force a module’s code to be reloaded and rerun, you need to ask Python to do so explicitly by calling the `reload` built-in function.

- Imports (via both `import` and `from` statements) load and run a module’s code only the first time the module is imported in a process.
- Later imports use the already loaded module object without reloading or rerunning the file’s code.
- The `reload` function forces an already loaded module’s code to be reloaded and rerun. Assignments in the file’s new code change the existing module object in place.

dynamic customization: the `reload` function allows parts of a program to be changed without stopping the whole program. With `reload`, the effects of changes in components can be observed immediately.

Reloading doesn’t help in every situation, but where it does, it makes for a much shorter development cycle.

> note that `reload` currently only works on modules written in Python; compiled extension modules coded in a language such as C can be dynamically loaded at runtime, too, but they can’t be reloaded (though most users probably prefer to code customizations in Python anyhow!).

> **Version skew note:** 
>
> In Python 2.X, reload is available as a built-in function.
>
> In Python 3.X, it has been moved to the `imp` standard library module—it’s known as `imp.reload` in 3.X.



#### reload Basics

- reload is a function in Python, not a statement.


- reload is passed an existing module object, not a new name.



- reload lives in a module in Python 3.X and must be imported itself.

Because `reload` expects an object, a module must have been previously imported successfully before you can reload it (if the import was unsuccessful due to a syntax or other error, you may need to repeat it before you can reload the module)

```
import module 						# Initial import
...use module.attributes... 
...									# Now, go change the module file
...
from imp import reload 				# Get reload itself (in 3.X)
reload(module) 						# Get updated exports
...use module.attributes...
```

When you call `reload`, Python rereads the module file’s source code and reruns its top-level statements. it changes a module object in place; it does not delete and re-create the module object.

- **reload runs a module file’s new code in the module’s current namespace.**Rerunning a module file’s code overwrites its existing namespace, rather than deleting and re-creating it.
- **Top-level assignments in the file replace names with new values**. For instance, rerunning a `def` statement replaces the prior version of the function in the module’s namespace by reassigning the function name.
- **Reloads impact all clients that use import to fetch modules**. Because clients that use import qualify to fetch attributes, they’ll find new values in the module object after a reload.
- **Reloads impact future from clients only**. Clients that used from to fetch attributes in the past won’t be affected by a reload; they’ll still have references to the old objects fetched before the reload.
- **Reloads apply to a single module only**. You must run them on each module you wish to update, unless you use code or tools that apply reloads transitively.



#### reload Example

1. write a module file named `changer.py` with the following contents:

```
message = "First version" 
def printer():
	print(message)
```

2. start the Python interpreter：

```
% python
>>> import changer
>>> changer.printer() 
First version
```

3. Keeping the interpreter active, now edit the module file in another window:

```
message = "After editing" 
def printer():
	print('reloaded:', message)
```

4. return to Python interpreter：

```
...back to the Python interpreter...

>>> import changer
>>> changer.printer() 					# No effect: uses loaded module
First version
>>> from imp import reload
>>> reload(changer) 					# Forces new code to load/run 
<module 'changer' from '.\\changer.py'>
>>> changer.printer() 					# Runs the new version now 
reloaded: After editing

--------------------------------------------------------------------------------------------------

>>> import changer
>>> changer.printer() 					# No effect: uses loaded module
First version
>>> import imp
>>> imp.reload(changer)
<module 'changer' from '.\\changer.py'>
>>> changer.printer() 					# Runs the new version now 
reloaded: After editing
```

> Notice that `reload` actually returns the module object for us—its result is usually ig-nored, but because expression results are printed at the interactive prompt, Python shows a default `<module 'name'...>` representation.



# 3. Module Packages

an import can name a directory path. A directory of Python code is said to be a package, so such imports are known as package imports. In effect, a package import turns a directory on your computer into another Python name-space, with attributes corresponding to the subdirectories and module files that the directory contains.

### Package Import Basics

package imports, list a path of names separated by periods:

```
import dir1.dir2.mod
```

The same goes for `from` statements:

```
from dir1.dir2.mod import x
```

#### Packages and Search Path Settings

You cannot use an invalid statement like this:

```
import C:\mycode\dir1\dir2\mod		# Error: illegal syntax
```

But you can add `C:\mycode` to your **PYTHONPATH** variable or a `.pth` file, and say this in your script:

```
import dir1.dir2.mod
```

#### Package `__init__.py` Files

If you choose to use package imports, there is one more constraint you must follow: at least until Python 3.3, each directory named within the path of a package import statement must contain a file named `__init__.py`, or your package imports will fail.

in the **Example**, both `dir1` and `dir2` must contain a file called `__init__.py`; the container directory `dir0` does not require such a file because it’s not listed in the `import` statement itself.

for a directory structure such as this:

```
dir0\dir1\dir2\mod.py
```

and an import statement of the form:

```
import dir1.dir2.mod
```

the following rules apply:

- `dir1` and `dir2` both must contain an `__init__.py` file.


- `dir0`, the container, does not require an `__init__.py` file; this file will simply be ignored if present.


- `dir0`, not `dir0\dir1`, must be listed on the module search path `sys.path`.

`dir0` must be an automatic path component (the home, libraries, or site-packages directories), or be given in **PYTHONPATH** or `.pth` file settings or manual `sys.path` changes.

this **Example**’s directory structure should be as follows, with indentation designating directory nesting:

```
dir0\						# Container on module search path
	dir1\ 
		__init__.py 
		dir2\ 
			__init__.py 
			mod.py
```

The `__init__.py` files can contain Python code, just like normal module files. Their names are special because **their code is run automatically the first time a Python program imports a directory**, and thus serves primarily as a hook for performing initialization steps required by the package. **These files can also be completely empty**

#### Package initialization file roles

the `__init__.py` file serves as a hook for package initialization-time actions, declares a directory as a Python package, generates a module namespace for a directory, and implements the behavior of `from *` (i.e., `from .. import *`) statements when used with directory imports:

- **Package initialization**

  The first time a Python program imports through a directory, it automatically runs all the code in the directory’s `__init__.py` file. Because of that, these files are a natural place to put code to initialize the state required by files in a package.

- **Module usability declarations**

  In the package import model, the directory paths in your script become real nested object paths after an import. For instance, in the preceding example, after the import the expression `dir1.dir2` works and returns a module object whose namespace contains all the names assigned by `dir2`’s `__init__.py` initialization file. Such files provide a namespace for module objects created for directories, which would otherwise have no real associated module file.

- **`from *` statement behavior**

  As an advanced feature, you can use `__all__` lists in `__init__.py` files to define what is exported when a directory is imported with the `from *` statement form. In an `__init__.py` file, the `__all__` list is taken to be the list of submodule names that should be automatically imported when `from *` is used on the package (directory) name. If `__all__` is not set, the `from *` statement does not automatically load sub-modules nested in the directory; instead, it loads just names defined by assignments in the directory’s `__init__.py` file, including any submodules explicitly imported by code in this file. For instance, the statement `from submodule import X` in a directory’s `__init__.py` makes the name X available in that directory’s namespace.

You can also simply leave these files empty, if their roles are beyond your needs (and frankly, they are often empty in practice). They must exist, though, for your directory imports to work at all.

**Note :**

Don’t confuse package `__init__.py` files with the class `__init__` constructor methods . The former are files of code run when imports first step through a package directory in a program run, while the latter are called when an instance is created. Both have initialization roles, but they are otherwise very different.



### Package Import Example

The following three files are coded in a directory dir1 and its subdirectory dir2—comments give the pathnames of these files:

```
# dir1\__init__.py 
print('dir1 init') 
x = 1

# dir1\dir2\__init__.py 
print('dir2 init') 
y = 2

# dir1\dir2\mod.py 
print('in mod.py') 
z = 3
```

`dir1` will be either an immediate subdirectory of the one we’re working in (i.e., the home directory), or an immediate subdirectory of a directory that is listed on the module search path (technically, on `sys.path`). Either way, `dir1`’s container does not need an `__init__.py` file.

`import` statements run each directory’s initialization file the first time that directory is traversed, as Python descends the path; `print` statements are included here to trace their execution:

```
C:\code> python					# Run in dir1's container directory
>>> import dir1.dir2.mod		# First imports run init files
dir1 init
dir2 init
in mod.py
>>> 
>>> import dir1.dir2.mod		# Later imports do not
```

an already imported directory may be passed to `reload` to force reexecution of that single item. As shown here, `reload` accepts a dotted pathname to reload nested directories and files:

```
>>> from imp import reload		# from needed in 3.X only
>>> reload(dir1) 
dir1 init 
<module 'dir1' from '.\\dir1\\__init__.py'>
>>>
>>> reload(dir1.dir2) 
dir2 init 
<module 'dir1.dir2' from '.\\dir1\\dir2\\__init__.py'>
```

Once imported, the path in your `import` statement becomes a nested object path in your script.

```
>>> dir1 
<module 'dir1' from '.\\dir1\\__init__.py'>
>>> dir1.dir2 
<module 'dir1.dir2' from '.\\dir1\\dir2\\__init__.py'>
>>> dir1.dir2.mod 
<module 'dir1.dir2.mod' from '.\\dir1\\dir2\\mod.py'>
```

#### from Versus import with Packages

`import` statements can be somewhat inconvenient to use with packages, because you may have to retype the paths frequently in your program.

It’s often more convenient, therefore, to use the `from` statement with packages to avoid retyping the paths at each access.

```
C:\code> python
>>> from dir1.dir2 import mod 				# Code path here only
dir1 init 
dir2 init 
in mod.py
>>> mod.z 									# Don't repeat path
3
>>> from dir1.dir2.mod import z
>>> z 
3
>>> import dir1.dir2.mod as mod				# Use shorter name
>>> mod.z 
3
>>> from dir1.dir2.mod import z as modz		# Ditto if names clash
>>> modz 
3
```



### Why Use Package Imports?

#### A Tale of Three Systems

Suppose that a programmer develops a Python program that contains a file called utilities.py for common utility code, and a top-level file named main.py that users launch to start the program. All over this program, its files say `import utilities` to load and use the common code. When the program is shipped, it arrives as a single .tar or .zip file containing all the program’s files, and when it is installed, it unpacks all its files into a single directory named system1 on the target machine:

```
system1\
	utilities.py 		# Common utility functions, classes
	main.py 			# Launch this to start the program
	other.py			# Import utilities to load my tools
```

Now, suppose that a second programmer develops a different program with files also called utilities.py and main.py, and again uses import utilities throughout the program to load the common code file. When this second system is fetched and installed on the same computer as the first system, its files will unpack into a new directory called system2 somewhere on the receiving machine—ensuring that they do not overwrite same-named files from the first system:

```
system2\
	utilities.py 		# Common utilities
	main.py 			# Launch this to run
	other.py			# Imports utilities
```

module search path settings are only needed to import across directory boundaries.

However, suppose that after you’ve installed these two programs on your machine, you decide that you’d like to use some of the code in each of the utilities.py files in a system of your own. It’s common utility code, after all, and Python code by nature “wants” to be reused. In this case, you’d like to be able to say the following from code that you’re writing in a third directory to load one of the two files:

```
import utilities 
utilities.func('spam')
```

Rather than installing programs in independent directories listed on the module search path individually, you can package and install them as subdirectories under a common root. For instance, you might organize all the code in this example as an install hierarchy that looks like this:

```
root\
	system1\
    	__init__.py 
    	utilities.py 
    	main.py 
    	other.py 
    system2\ 
    	__init__.py 
    	utilities.py 
    	main.py 
    	other.py 
    system3\ 				# Here or elsewhere
    	__init__.py 		# Need __init__.py here only if imported elsewhere
    	myfile.py			# Your new code here
```

**add just the common root directory to your search path**. If your code’s imports are all relative to this common root, you can import either system’s utility file with a package import—the enclosing directory name makes the path (and hence, the module reference) unique

```
import system1.utilities 
import system2.utilities 
system1.utilities.function('spam') 
system2.utilities.function('eggs')
```

The names of the enclosing directories here make the module references unique.

- Note that you have to use `import` instead of `from` with packages only if you need to access the same attribute name in two or more paths. If the name of the called function here were different in each path, you could use `from` statements to avoid repeating the full package path whenever you call one of the functions


- `__init__.py` files were added to the system1 and system2 directories to make this work, but not to the root directory. Only directories listed within `import` statements in your code require these files, they are run automatically the first time the Python process imports through a package directory.
- in this case the system3 directory doesn’t have to be under root—just the packages of code from which you will import. However, because you never know when your own modules might be useful in other programs, you might as well place them under the common root directory as well to avoid similar name-collision problems in the future.
- notice that both of the two original systems’ imports will keep working un-changed. Because their home directories are searched first, the addition of the common root on the search path is irrelevant to code in system1 and system2; they can keep saying just `import utilities` and expect to find their own files when run as programs —though not when used as packages in 3.X, as the next section explains. If you’re careful to unpack all your Python systems under a common root like this, path configuration also becomes simple: you’ll only need to add the common root directory once.


### Package Relative Imports

Python 2.X implicitly searches package directories first on imports, while 3.X requires explicit relative import syntax in order to import from the package directory.

#### Changes in Python 3.X

- It modifies the module import search path semantics to skip the package’s own directory by default. Imports check only paths on the `sys.path` search path. These are known as absolute imports.


- It extends the syntax of `from` statements to allow them to explicitly request that imports search the package’s directory only, with leading dots. This is known as relative import syntax.

The impact of this change is that in 3.X (and optionally in 2.X), you must generally use special `from` dotted syntax to import modules located in the same package as the im-porter, unless your imports list a complete path relative to a package root on `sys.path`, or your imports are relative to the always-searched home directory of the program’s top-level file (which is usually the current working directory).

#### Relative Import Basics

In both Python 3.X and 2.X, `from` statements can now use leading dots (“.”) to specify that they require modules located within the same package (known as package relative imports), instead of modules located elsewhere on the module import search path (called absolute imports). That is:

- Imports with dots: In both Python 3.X and 2.X, you can use leading dots in `from` statements’ module names to indicate that imports should be relative-only to the containing package—such imports will search for modules inside the package directory only and will not look for same-named modules located elsewhere on the import search path (`sys.path`). The net effect is that package modules override outside modules.
- Imports without dots: In Python 2.X, normal imports in a package’s code without leading dots currently default to a relative-then-absolute search path order—that is, the y search the package’s own directory first. However, in Python 3.X, normal imports within a package are absolute-only by default—in the absence of any special dot syntax, imports skip the containing package itself and look elsewhere on the `sys.path` search path.

For **example**, in both Python 3.X and 2.X a statement of the form:

```
from . import spam		# Relative to this package
```

instructs Python to import a module named `spam` located in the same package directory as the file in which this statement appears. Similarly, this statement:

```
from .spam import name
```

means “from a module named `spam` located in the same package as the file that contains this statement, import the variable `name`.”

in 3.X’s model, a statement of the following form will always find a `string` module somewhere on sys.path, instead of a module of the same name in the package:

```
import string		# Skip this package's version
```

By contrast, without the from `__future__` statement in 2.X, if there’s a local string module in the package, it will be imported instead.

**Notice that leading dots can be used to force relative imports only with the `from` statement, not with the `import` statement.** 

**In Python 3.X, the `import modname` statement is always absolute-only, skipping the containing package’s directory.** 

**In 2.X, this statement form still performs relative imports, searching the package’s directory first. `from` statements without leading dots behave the same as `import` statements—absolute-only in 3.X (skipping the package directory), and relative-then-absolute in 2.X (searching the package directory first).**

Within a module file located in a package directory named `mypkg`, the following alternative import forms work as described:

```
from .string import name1, name2 		# Imports names from mypkg.string
from . import string 					# Imports mypkg.string
from .. import string					# Imports string sibling of mypkg
```

#### Why Relative Imports?

this feature is designed in part to allow scripts to resolve ambiguities that can arise when a same-named file appears in multiple places on the module search path. Consider the following package directory:

```
mypkg\
	__init__.py 
	main.py 
	string.py
```

#### The relative imports solution in 3.X

an `import` statement of the following form in our example file mypkg/main.py will always find a `string` module outside the package, via an absolute import search of `sys.path`:

```
import string		# Imports string outside package (absolute)
```

A `from` import without leading-dot syntax is considered absolute as well:

```
from string import name		# Imports name from string outside package
```

relative imports are still possible if you use the dot syntax in the `from` statement:

```
from . import string		# Imports mypkg.string here (relative)
```

 statement  refers to the `string` module relative to the current package. If this code appears in our `mypkg.main` module, for example, it will import `name1` and `name2` from `mypkg.string`.

```
from .string import name1, name2		# Imports names from mypkg.string
```

the “.” in a relative import is taken to stand for the package directory containing the file in which the import appears. An additional leading dot performs the relative import starting from the parent of the current package.

```
from .. import spam		# Imports a sibling of mypkg
```

code located in some module A.B.C can use any of these forms:

```python
from . import D 		# Imports A.B.D (. means A.B)
from .. import E 		# Imports A.E (.. means A)
from .D import X 		# Imports A.B.D.X (. means A.B)
from ..E import X		# Imports A.E.X (.. means A)
```

#### Relative imports versus absolute package paths

