

# Generator

通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。所以，如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。**在Python中，这种一边循环一边计算的机制，称为生成器：generator。**

要创建一个generator。第一种方法，把一个列表生成式的`[]`改成`()`：

```
>>> L = [x * x for x in range(10)]				
>>> L											# L是一个list
[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
>>> g = (x * x for x in range(10))
>>> g
<generator object <genexpr> at 0x1022ef630>		# g是一个generator
```

> 如果要一个一个打印出来，可以通过`next()`函数获得generator的下一个返回值：

> ```
> >>> next(g)					# generator保存的是算法，每次调用next(g)，就计算出g的下一个元素的值
> 0
> >>> next(g)
> 1
> >>> next(g)
> 4
> >>> next(g)
> 9
> >>> next(g)
> 16
> >>> next(g)
> 25
> >>> next(g)
> 36
> >>> next(g)
> 49
> >>> next(g)
> 64
> >>> next(g)
> 81
> >>> next(g)
> Traceback (most recent call last):				# 没有更多的元素时，抛出StopIteration的错误。
>   File "<stdin>", line 1, in <module>
> StopIteration
> ```

正确的方法是使用 `for` 循环，因为generator也是可迭代对象：

```
>>> g = (x * x for x in range(10))
>>> for n in g:
...     print(n)
... 
0
1
4
9
16
25
36
49
64
81
```



# Generator Functions and Expressions

two language constructs delay result creation whenever possible in user-defined operations:

- Generator functions (available since 2.3) are coded as normal `def` statements, but use `yield` statements to return results one at a time, suspending and resuming their state between each.


- Generator expressions (available since 2.4) are similar to the list comprehensions of the prior section, but they return an object that produces results on demand instead of building a result list.

Because neither constructs a result list all at once, they save memory space and allow computation time to be split across result requests.



## Generator Functions: yield Versus return

functions that may send back a value and later be resumed, picking up where they left off. Such functions, available in both Python 2.X and 3.X, are known as **generator** functions because they generate a sequence of values over time.

> Generator functions are like normal functions in most respects, and in fact are coded with normal `def` statements. However, when created, they are compiled specially into an object that supports the iteration protocol. And when called, they don’t return a result: they return a result generator that can appear in any iteration context.

### State suspension

generator functions automatically suspend and resume their execution and state around the point of value generation. Because of that, they are often a useful alternative to both computing an entire series of values up front and manually saving and restoring state in classes. The state that generator functions retain when they are suspended includes both their code location, and their entire local scope. Hence, their local variables retain information between results, and make it available when the functions are resumed.

The chief code difference between generator and normal functions is that a generator yields a value, rather than returning one—the yield statement suspends the function and sends a value back to the caller, but retains enough state to enable the function to resume from where it left off. When resumed, the function continues execution immediately after the last `yield` run. From the function’s perspective, this allows its code to produce a series of values over time, rather than computing them all at once and sending them back in something like a list.

### Iteration protocol integration

generator functions are closely bound up with the notion of the iteration protocol in Python.

iterator objects define a `__next__` method (`next` in 2.X), which either returns the next item in the iter-ation, or raises the special `StopIteration` exception to end the iteration. An iterable object’s iterator is fetched initially with the `iter` built-in function, though this step is a no-op for objects that are their own iterator.

To support this protocol, functions containing a `yield` statement are compiled specially as **generators**—they are not normal functions, but rather are built to return an object with the expected iteration protocol methods. When later called, they return a generator object that supports the iteration interface with an automatically created method named `__next__` to start or resume execution.

Generator functions may also have a `return` statement that, along with falling off the end of the `def` block, simply terminates the generation of values—technically, by raising a `StopIteration` exception after any normal function exit actions. From the caller’s perspective, the generator’s `__next__` method resumes the function and runs until either the next `yield` result is returned or a `StopIteration` is raised.

The net effect is that generator functions, coded as `def` statements containing `yield` statements, are automatically made to support the iteration object protocol and thus may be used in any iteration context to produce results over time and on demand.

### Generator functions in action

The following code defines a generator function that can be used to generate the squares of a series of numbers over time:

```
>>> def gensquares(N):
...     for i in range(N):
...         yield i ** 2		# Resume here later
```

This function yields a value, and so returns to its caller, each time through the loop; when it is resumed, its prior state is restored, including the last values of its variables i and N, and control picks up again immediately after the `yield` statement. For example, when it’s used in the body of a `for` loop, the first iteration starts the function and gets its first result; thereafter, control returns to the function after its `yield` statement each time through the loop:

```
>>> for i in gensquares(5):		# Resume the function
...     print(i, end=' : ')		# Print last yielded value
... 
0 : 1 : 4 : 9 : 16 : 
```

To end the generation of values, functions either use a `return` statement with no value or simply allow control to fall off the end of the function body.

to see what is going on inside the for, call the generator function directly:

```
>>> x = gensquares(4)
>>> x 
<generator object gensquares at 0x000000000292CA68>
```

the `next(X)` built-in calls an object’s `X.__next__()` method for us in 3.X (and `X.next()` in 2.X):

```
>>> next(x)			# Same as x.__next__() in 3.X
0
>>> next(x)			# Use x.next() or next() in 2.X
1
>>> next(x)
4
>>> next(x)
9
>>> next(x)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration
```

`for` loops (and other iteration contexts) work with generators in the same way—by calling the `__next__` method repeatedly, until an exception is caught. For a generator, the result is to produce yielded values over time. If the object to be iterated over does not support this protocol, `for` loops instead use the indexing protocol to iterate.

generators are their own iterator, supporting just one active iteration scan. To put that another way generators return themselves for `iter`, because they support `next` directly

```
>>> y = gensquares(5)		# Returns a generator which is its own iterator
>>> iter(y) is y			# iter() is not required: a no-op here
True
>>> next(y)					# Can run next()immediately
0
```

### Why generator functions?

build the list of yielded values all at once:

```
>>> def buildsquares(n):
...     res = []
...     for i in range(n): res.append(i ** 2)
...     return res
... 
>>> for x in buildsquares(5): print(x, end = ' : ')
... 
0 : 1 : 4 : 9 : 16 : 
```

use any of the for loop, map, or list comprehension techniques:

```
>>> for x in [n ** 2 for n in range(5)]:
...     print(x, end=' : ')
... 
0 : 1 : 4 : 9 : 16 : 
>>> 
>>> for x in map((lambda n: n ** 2), range(5)):
...     print(x, end=' : ')
... 
0 : 1 : 4 : 9 : 16 : 
```

They can operate on and return any type of object, and as iterables may appear in any of  iteration contexts, including `tuple` calls, enumerations, and dictionary comprehensions:

```
>>> def ups(line):
...     for sub in line.split(','):		# Substring generator
...         yield sub.upper()
... 

>>> tuple(ups('aaa,bbb,ccc'))			# All iteration contexts
('AAA', 'BBB', 'CCC')

>>> {i: s for (i, s) in enumerate(ups('aaa,bbb,ccc'))} 
{0: 'AAA', 1: 'BBB', 2: 'CCC'}
```

### Extended generator function protocol: send versus next

In Python 2.5, a `send` method was added to the generator function protocol. The send method advances to the next item in the series of results, just like `__next__`, but also provides a way for the caller to communicate with the generator, to affect its operation.

`yield` is now an expression form that returns the item passed to send, not a statement (though it can be called either way—as `yield X`, or `A = (yield X)`).The expression must be enclosed in parentheses unless it’s the only item on the right side of the assignment statement. For example, `X = yield Y` is OK, as is `X = (yield Y) + 42`.

When this extra protocol is used, values are sent into a generator `G` by calling `G.send(value)`. The generator’s code is then resumed, and the `yield` expression in the generator returns the value passed to `send`. If the regular `G.__next__()` method (or its `next(G)` equivalent) is called to advance, the `yield` simply returns `None`.

example:

```
>>> def gen():
...     for i in range(10):
...         X = yield i
...         print(X)
... 
>>> G = gen()
>>> next(G)				# Must call next() first, to start generator
0
>>> G.send(77)			# Advance, and send value to yield expression
77
1
>>> G.send(88)
88
2
>>> next(G)				# next() and X.__next__() send None
None
3
```

the `__next__` method applies to all iterable objects—both built-in types and user-defined classes.



## Generator Expressions: Iterables Meet Comprehensions

In both Python 2.X and 3.X, the notions of iterables and list comprehensions are combined in a new tool: generator expressions.

> generator expressions are just like normal list comprehensions, and support all their syntax —including if filters and loop nesting—but they are enclosed in parentheses instead of square brackets (like tuples, their enclosing parentheses are often optional):

```
>>> [x ** 2 for x in range(4)]	# List comprehension: build a list
[0, 1, 4, 9]
>>> (x ** 2 for x in range(4))	# Generator expression: make an iterable
<generator object <genexpr> at 0x101139fc0>
```

at least on a functionality basis, coding a list comprehension is essentially the same as wrapping a generator expression in a `list` built-in call to force it to produce all its results in a list at once:

```
>>> list(x ** 2 for x in range(4)) 	# List comprehension equivalence
[0, 1, 4, 9]
```

generator expressions are very different: instead of building the result list in memory, they return a generator object—an automatically created iterable. This iterable object in turn supports the iteration protocol to yield one piece of the result list at a time in any iteration context. The iterable object also retains gen-erator state while active—the variable x in the preceding expressions, along with the generator’s code location.

```
>>> G = (x ** 2 for x in range(4))
>>> iter(G) is G			# iter(G) optional: __iter__ returns self
True
>>> next(G)					# Generator objects: automatic methods
0
>>> next(G)
1
>>> next(G)
4
>>> next(G)
9
>>> next(G)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration
>>> G
<generator object <genexpr> at 0x1011dc048>
```

for loops trigger the `next` iterator for us automatically: (every iteration context does this)

```
>>> for num in (x ** 2 for x in range(4)):	# Calls next() automatically
    	print('%s, %s' % (num, num / 2.0)) 
0, 0.0 
1, 0.5 
4, 2.0 
9, 4.5
```

parentheses are not required around a generator expression that is the sole item already enclosed in parentheses used for other purposes. Parentheses are required in all other cases, however, even if they seem extra, as in the second call to `sorted` that follows:

```
>>> sum(x ** 2 for x in range(4)) 			# Parens optional
14
>>> sorted(x ** 2 for x in range(4)) 		# Parens optional
[0, 1, 4, 9]
>>> sorted((x ** 2 for x in range(4)), reverse=True) 	# Parens optional
[9, 4, 1, 0]
```

### Why generator expressions?

Just like generator functions, generator expressions are a memory-space optimization —they do not require the entire result list to be constructed all at once, as the square-bracketed list comprehension does. Also like generator functions, they divide the work of results production into smaller time slices—they yield results in piecemeal fashion, instead of making the caller wait for the full set to be created in a single call.

generator expressions may also run slightly slower than list comprehensions in practice, so they are probably best used only for very large result sets, or applications that cannot wait for full results generation. A more authoritative statement about performance,

### Generator expressions versus map

generator expressions often are equivalent to 3.X map calls, because both generate result items on request.

```
>>> list(map(abs, (−1, −2, 3, 4))) 				# Map function on tuple
[1, 2, 3, 4]
>>> list(abs(x) for x in (−1, −2, 3, 4)) 		# Generator expression
[1, 2, 3, 4]
>>> list(map(lambda x: x * 2, (1, 2, 3, 4))) 	# Nonfunction case
[2, 4, 6, 8]
>>> list(x * 2 for x in (1, 2, 3, 4)) 			# Simpler as generator?
[2, 4, 6, 8]
```



```
>>> line = 'aaa,bbb,ccc'
>>> ''.join([x.upper() for x in line.split(',')]) # Makes a pointless list
'AAABBBCCC'

>>> ''.join(x.upper() for x in line.split(',')) 	# Generates results
'AAABBBCCC'
>>> ''.join(map(str.upper, line.split(','))) 		# Generates results
'AAABBBCCC'

>>> ''.join(x * 2 for x in line.split(',')) 		# Simpler as generator?
'aaaaaabbbbbbcccccc'
>>> ''.join(map(lambda x: x * 2, line.split(','))) 
'aaaaaabbbbbbcccccc'
```

Both map and generator expressions can also be arbitrarily nested,

```
>>> [x * 2 for x in [abs(x) for x in (−1, −2, 3, 4)]] 
[2, 4, 6, 8]										# Nested comprehensions

>>> list(map(lambda x: x * 2, map(abs, (−1, −2, 3, 4)))) 
[2, 4, 6, 8]										# Nested maps

>>> list(x * 2 for x in (abs(x) for x in (−1, −2, 3, 4))) 
[2, 4, 6, 8]										# Nested generators
```

combine operations, the generators do so without making multiple temporary lists.

```
>>> import math
>>> list(map(math.sqrt, (x ** 2 for x in range(4)))) 
[0.0, 1.0, 2.0, 3.0]								# Nested combinations
```



#### ...

#### ...

#### ...